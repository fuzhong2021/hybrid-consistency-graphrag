{
  "timestamp": "2026-02-22T13:31:04.699038",
  "dataset": "hotpotqa",
  "sample_size": 5,
  "config": {
    "embedding_model": "all-MiniLM-L6-v2",
    "use_gpu": true,
    "missing_source_penalty": 0.7,
    "cardinality_rules": {
      "ANSWERS": 1,
      "HAS_ANSWER": 1
    },
    "source_verification_enabled": true
  },
  "phases": {
    "phase1_baseline": {
      "phase_name": "Phase 1: Baseline (GOLD)",
      "total_triples": 9,
      "accepted": 9,
      "rejected": 0,
      "conflicts_detected": 0,
      "avg_confidence": 0.3172222222222223,
      "min_confidence": 0.225,
      "max_confidence": 0.4675,
      "missing_source_warnings": 0,
      "penalties_applied": 0,
      "corroborated_facts": 0,
      "processing_time_seconds": 2.3406388759613037,
      "true_positives": 0,
      "false_negatives": 0,
      "true_negatives": 9,
      "false_positives": 0,
      "acceptance_rate": 1.0,
      "rejection_rate": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "f1_score": 0.0
    },
    "phase2_correct_with_source": {
      "phase_name": "Phase 2: Korrekt MIT Quelle",
      "total_triples": 9,
      "accepted": 8,
      "rejected": 1,
      "conflicts_detected": 0,
      "avg_confidence": 0.3825,
      "min_confidence": 0.225,
      "max_confidence": 0.4675,
      "missing_source_warnings": 0,
      "penalties_applied": 0,
      "corroborated_facts": 0,
      "processing_time_seconds": 0.06622004508972168,
      "true_positives": 0,
      "false_negatives": 0,
      "true_negatives": 8,
      "false_positives": 1,
      "acceptance_rate": 0.8888888888888888,
      "rejection_rate": 0.1111111111111111,
      "precision": 0.0,
      "recall": 0.0,
      "f1_score": 0.0
    },
    "phase3_correct_without_source": {
      "phase_name": "Phase 3: Korrekt OHNE Quelle",
      "total_triples": 9,
      "accepted": 8,
      "rejected": 1,
      "conflicts_detected": 0,
      "avg_confidence": 0.2876893895213294,
      "min_confidence": 0.1575,
      "max_confidence": 0.3886694821428573,
      "missing_source_warnings": 8,
      "penalties_applied": 8,
      "corroborated_facts": 0,
      "processing_time_seconds": 0.00494694709777832,
      "true_positives": 0,
      "false_negatives": 0,
      "true_negatives": 8,
      "false_positives": 1,
      "acceptance_rate": 0.8888888888888888,
      "rejection_rate": 0.1111111111111111,
      "precision": 0.0,
      "recall": 0.0,
      "f1_score": 0.0
    },
    "phase4_distractor_contradictions": {
      "phase_name": "Phase 4: Kardinalit√§ts-Violations",
      "total_triples": 10,
      "accepted": 2,
      "rejected": 8,
      "conflicts_detected": 0,
      "avg_confidence": 0.33999999999999997,
      "min_confidence": 0.27999999999999997,
      "max_confidence": 0.4,
      "missing_source_warnings": 0,
      "penalties_applied": 0,
      "corroborated_facts": 0,
      "processing_time_seconds": 0.0240170955657959,
      "true_positives": 8,
      "false_negatives": 2,
      "true_negatives": 0,
      "false_positives": 0,
      "acceptance_rate": 0.2,
      "rejection_rate": 0.8,
      "precision": 1.0,
      "recall": 0.8,
      "f1_score": 0.888888888888889
    },
    "phase5_cross_question_confusion": {
      "phase_name": "Phase 5: Cross-Question Violations",
      "total_triples": 5,
      "accepted": 1,
      "rejected": 4,
      "conflicts_detected": 0,
      "avg_confidence": 0.2,
      "min_confidence": 0.2,
      "max_confidence": 0.2,
      "missing_source_warnings": 0,
      "penalties_applied": 0,
      "corroborated_facts": 0,
      "processing_time_seconds": 0.0076029300689697266,
      "true_positives": 4,
      "false_negatives": 1,
      "true_negatives": 0,
      "false_positives": 0,
      "acceptance_rate": 0.2,
      "rejection_rate": 0.8,
      "precision": 1.0,
      "recall": 0.8,
      "f1_score": 0.888888888888889
    },
    "phase6_fake_source_attack": {
      "phase_name": "Phase 6: Fake Source Attack",
      "total_triples": 5,
      "accepted": 5,
      "rejected": 0,
      "conflicts_detected": 0,
      "avg_confidence": 0.23138065102040822,
      "min_confidence": 0.21048401020408164,
      "max_confidence": 0.24750000000000003,
      "missing_source_warnings": 0,
      "penalties_applied": 0,
      "corroborated_facts": 0,
      "processing_time_seconds": 0.09846186637878418,
      "true_positives": 0,
      "false_negatives": 5,
      "true_negatives": 0,
      "false_positives": 0,
      "acceptance_rate": 1.0,
      "rejection_rate": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "f1_score": 0.0
    }
  },
  "comparison_metrics": {
    "missing_source_penalty_effectiveness": 0.24787087706841993,
    "contradiction_detection_f1": 0.888888888888889,
    "cross_question_detection_f1": 0.888888888888889,
    "fake_source_detection_effectiveness": 0.3950832653061223
  }
}